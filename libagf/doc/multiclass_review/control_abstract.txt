Many of the best statistical classification algorithms are binary classifiers
that can only distinguish between one of two classes.
The number of possible ways of generalizing binary classification to
multi-class increases exponentially with the number of classes.
There is some indication that the best method so will depend on the dataset. 
Hence, we are particularly interested in data-driven solution design, 
whether based on
prior considerations or on empirical examination of the data.
Here we demonstrate how a recursive control language can be used to describe
a multitude of different partitioning strategies in multi-class classification,
including those in most common use.
We use it both to manually construct new partitioning configurations as well 
as to examine those that have been automatically designed.
Eight different strategies are tested on eight different datasets using
a support vector machine (SVM) as the base binary classifier.
Numerical tests suggest that a one-size-fits-all solution consisting of 
one-versus-one is appropriate for most datasets.
Three datasets showed better accuracy using different methods.
The best solution for the most improved dataset 
exploited a property of the data to produce
an uncertainty coefficient 36\% higher (0.016 absolute gain) than one-vs.-one.
For the same dataset, 
an adaptive solution that empirically examined the data was also more
accurate than one-vs.-one while being faster.

