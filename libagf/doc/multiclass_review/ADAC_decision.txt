[Manuscript was received on Sept. 21, 2019, review was sent Jan 25, 2020.]


Dear Mr. Mills,

An Associate Editor and I have read your manuscript, ADAC-D-19-00298 "Optimizing class partitioning in multi-class classification using a descriptive control language"

With regret, I must inform you that I have decided that your paper cannot be accepted for publication in
Advances in Data Analysis and Classification.

Below, please find the comments for your perusal.

I would like to thank you very much for forwarding your manuscript to us for consideration and wish you every success in finding an alternative place of publication.

With kind regards,
Maurizio Vichi
Coordinating Editor
Advances in Data Analysis and Classification


Associate Editor

In this paper, the authors provide an overview of techniques for reducing multi-class to binary classification problems. Moreover, they propose a "control language" for specifying corresponding reductions. Finally, they compare several binary decompositions schemes on a few benchmark data sets from the UCI library.

The paper is well organized, clearly written, and easy to follow. That said, the contribution of the paper does not appear to be significant enough to warrant publication in ADAC.

-- The overview of decomposition techniques in Sections 2-4 might be a good introduction to the topic. However, there is nothing new here, and similar overviews can be found in the machine learning literature.

-- Section 4 contributes to a possible notational confusion, because the term "decision tree" has another meaning in the machine learning literature. For the hierarchical decomposition scheme the authors are speaking about here, other names are used, such as "nested dichotomy" [1]. Moreover, this section is not up to date, because recent publications on the topic are missing, for example on the data-driven (empirical) construction of hierarchical decompositions [2,3].

-- The "control language" introduced in Section 5 is a very simple formal description of a binary decomposition. What is the (scientific) contribution here?

-- The experiments conducted in Section 6 and discussed in Section 7 do not create any new insights. Many studies of this kind can be found in the machine learning literature, where similar findings have been made (for example, that one-vs-one is robust and performs well on average). Besides, key references on the topic are again missing [4,5]. A thorough statistical analysis of the results is also missing.


References:

[1] E. Frank, S. Kramer. Ensembles of nested dichotomies for multi-class problems. Proc. International Conference on Machine Learning, ICML 2004.

[2] T. Leathart, B. Pfahringer, E. Frank. Building ensembles of adaptive nested dichotomies with random-pair selection. Proc. ECML/PKDD 2016.

[3] V. Melnikov, E. Hüllermeier. On the effectiveness of heuristics for learning nested dichotomies: an empirical analysis. Machine Learning, 107(8-10):1537-1560, 2018.

[4] R. Rifkin, A. Klautau. In defense of one-vs-all classification. Journal of Machine Learning Research 5, 101-141, 2004.

[5] J. Fürnkranz. Round robin classification. Journal of Machine Learning Research, 2:721-747, 2002.


