We review common methods of solving for multi-class from binary
and generalize them to a common framework.
Since conditional probabilties are useful both for quantifying the accuracy of
an estimate and for calibration purposes, 
these are a required part of the solution.
There is some indication that the best solution for multi-class classification
is dependent on the particular dataset.
As such, we are particularly interested in data-driven solution design, 
whether based on a priori considerations or empirical examination of the data.
Numerical results indicate that while
a one-size-fits-all solution consisting of one-versus-one 
is appropriate for most datasets,
a minority will benefit from a more customized approach.
The techniques discussed in this paper allow for a large variety of multi-class
configurations and solution methods to be explored so as to optimize 
classification accuracy, accuracy of conditional probabilities and speed.

