\documentclass{article}

\usepackage{natbib}

\bibliographystyle{apa}

\newcommand{\probability}{P}
\newcommand{\condprob}{P}
\newcommand{\estimate}{\tilde p}
\newcommand{\coord}{x}
\newcommand{\features}{\vec \coord}

\begin{document}

\title{A theorem for calibrating and validating conditional probabilities}

\author{Peter Mills}

\maketitle

\section{Introduction}

In regression and statistical classification, estimates may be validated
through direct comparision with the training data.
With density estimation, the existance of training data does not provide
a means of direct validation.
Here we are interested in validating conditional probability estimates from a
statistical classification algorithm.
\citet{Mills2009} describes a simple method of validation based on Bayes
theorem and the definition of probability.
The goal of this note is to validate this validation method.

\section{Theory}

From Bayes theorem and the definition of probability, we can write:
\begin{equation}
	\int P(\vec x) P(c | \vec x) \mathrm d \vec x = \lim_{N \rightarrow \infty} N_c/N
\end{equation}
where $N_c$ is the number of training samples of class $c$ and $N$ is the 
total number of training samples.
Transforming this into a Monte Carlo sum (with importance sampling):
\begin{equation}
	\lim_{N \rightarrow \infty} \left [ \sum_{i=1}^N P(c | \vec x_i) = N_c \right ]
\end{equation}
where $\vec x_i$ is the features data of $i$th training sample.
We use the Kronecker delta 
to move the equals sign outside the limit:
\begin{equation}
	\lim_{N \rightarrow \infty} \left [ \sum_{i=1}^N P(c | \vec x_i) - \delta_{cy_i} \right ] = 0 \label{theorem}
\end{equation}
where $y_i$ is the class of $i$th training sample.
From this it's easy to derive a variant which follows, on average, 
single step intervals in the trace:
\begin{equation}
	\lim_{N \rightarrow \infty} \left [N = \sum_{i=1}^N \frac{\delta_{cy_i}}{P(c|\vec x_i)} \right ]
\end{equation}
This equation will work only if all the conditional probabilities 
are non-zero ($P(c|\vec x_i) \ne 0$).
We can write a complementary equation that will work
if the conditional probabilities are sometimes zero but never exactly one ($P(c|\vec x_i) \ne 1$):
\begin{equation}
	\lim_{N \rightarrow \infty} \left [N = \sum_{i=1}^N \frac{1-\delta_{cy_i}}{1-P(c|\vec x_i)} \right ]
\end{equation}

To make the theorem useful for validation purposes there are two things 
to be done.
First, the estimated conditional probabilities, $\tilde p$, are sorted from
low to high:
\begin{equation}
	\tilde p(c_{i+1}|\vec x_{i+1}) \ge \tilde p(c_i|\vec x_i)
\end{equation}
Note that there is no need to separate out each class, hence the subscript
on the class label.
Second, we define the index, $i_0$, as the rank of the first ``winning''
probability estimate:
\begin{equation}
	\tilde p(c_i | \vec x_i) \ge 1/n \iff i \ge i_0
\end{equation}
where $n$ is the number of classes.
With this in place, Equation (\ref{theorem}) is divided into twp parts.
The first part counts up:
\begin{equation}
	\sum_{i=i_0}^{N^\prime+i_0} \delta_{c_iy_i} 
		\approx \sum_{i=i_0}^{N^\prime+i_0} \tilde p(c_i | \vec x_i) \\
\end{equation}
while the second part counts down:
\begin{equation}
	\sum_{i=N^\prime+i_0}^{i_0} \left [\delta_{c_iy_i}-1 \right ] 
	\approx \sum_{i=N^\prime+i_0}^{i_0} \left [\tilde p(c_i | \vec x_i) - 1 \right ]
	\label{second_part}
\end{equation}

Dividing means the the points don't bunch up towards the left-hand side of
the trace while the
threshold of $1/n$ means that most of the terms on the LHS should be non-zero.
Note (\ref{second_part}) can be rewritten:
\begin{equation}
	\sum_{i=N^\prime+i_0}^{i_0} \delta_{c_iy_i} - N^\prime
	\approx \sum_{i=N^\prime+i_0}^{i_0} \tilde p(c_i | \vec x_i) - N^\prime
\end{equation}
and that $N^\prime$ counts from $-i_0$ to $N-i_0$.

To use this for validation purposes,
the correlation coefficient can be used to measure the precision while the 
slope returns the bias.

\subsection{Use for calibration}

The theorem can be extended for calibration of decision values returned from
binary classifiers.
Note that calibration can itself be stated as a form of probability estimation.
Consider a binary classifier for which we wish to find the value of
$P(1|\vec x)$ as a function of $f$, the decision value:
\begin{equation}
	P(f) \approx \lim_{N \rightarrow \infty;\mathrm d f=0}
	\frac{\sum_{i=1|f \le f(\vec x_i) < f+\mathrm d f}^N \delta_{1 y_i}}
	{\sum_{i=1|f \le f(\vec x_i) < f+\mathrm d f}^N 1
\end{equation}
We start with the definition of probability which we define in terms of
the Kronecker delta:
\begin{equation}
	P(x) = \lim_{

\bibliography{../agf_bib}

\end{document}

